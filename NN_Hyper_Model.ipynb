{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8a63a7-3741-4b90-9246-68339c6cd91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "from tensorflow.keras import layers\n",
    "from sklearn import metrics\n",
    "import keras_tuner\n",
    "import seaborn as sns\n",
    "import struct\n",
    "import time\n",
    "import pickle\n",
    "import itertools\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fec7fd-6d4e-46a9-a69c-6bbf09b7f36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix. \n",
    "    Normalization can be applied by setting normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm. sum (axis=1)[:, np.newaxis] \n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:    \n",
    "        print('Confusion matrix, without normalization')\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product (range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j]> thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d614db-bcb5-4dd9-af4d-29f1e3472346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_idx(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b2e376-3869-4af4-b857-087d38bec960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dense(units=128, input_shape=(784,), activation='relu'))\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            # Tune number of units.\n",
    "            units=hp.Int(\"units\", min_value=32, max_value=512, step=16),\n",
    "            # Tune the activation function to use.\n",
    "            activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            # Tune number of units.\n",
    "            units=hp.Int(\"units\", min_value=96, max_value=512, step=16),\n",
    "            # Tune the activation function to use.\n",
    "            activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
    "        )\n",
    "    )\n",
    "    # Tune whether to use dropout.\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "    # Define the optimizer learning rate as a hyperparameter.\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0b9ac1-a715-4a21-8f93-9a3e0af40aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train = read_idx(\"train-images-idx3-ubyte\")\n",
    "train_data = raw_train / 255.0\n",
    "train_data = np.reshape(train_data, (60000, 28*28))\n",
    "train_label = read_idx(\"train-labels-idx1-ubyte\")\n",
    "raw_test = read_idx(\"t10k-images-idx3-ubyte\")\n",
    "test_data = raw_test / 255.0\n",
    "test_data = np.reshape(test_data, (10000, 28*28))\n",
    "test_label = read_idx(\"t10k-labels-idx1-ubyte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368eb15b-15f1-4c68-baef-ecfe1d3d6b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10 #number of classes, here is 10 (0,1,...,9)\n",
    "train_label = keras.utils.to_categorical(train_label, num_classes)\n",
    "test_label_cat = keras.utils.to_categorical(test_label, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cc5603-2c92-4ebf-9a62-deea6a561a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_model(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33828fb-7f60-4f54-9259-c55bb2f3baa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=10,\n",
    "    executions_per_trial=4,\n",
    "    overwrite=True,\n",
    "    directory=\"NN_Hyper_Test_DIR\",\n",
    "    project_name=\"NN_Hyper_Test\",\n",
    ")\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c46759-de83-4421-aa4d-3fe4cdf9f5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(train_data, train_label, batch_size=4096, epochs=16, validation_data=(test_data, test_label_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c9b979-b001-48d8-b869-1cfa13bc6663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 2 models.\n",
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "# Build the model.\n",
    "# Needed for `Sequential` without specified `input_shape`.\n",
    "best_model.build(input_shape=(None, 784))\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a1f05b-17d1-4bfb-815b-600e9ee87541",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f13d4c5-cf17-4bfd-ab24-c71b63725aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# Get the top 2 hyperparameters.\n",
    "best_hps = tuner.get_best_hyperparameters(5)\n",
    "# Build the model with the best hp.\n",
    "model = build_model(best_hps[0])\n",
    "X_Data = train_data\n",
    "Y_Data = train_label\n",
    "epochs=128\n",
    "batchsize = 4095\n",
    "model.fit(x=X_Data, y=Y_Data, batch_size = batchsize, epochs = epochs)\n",
    "end = time.time()\n",
    "print(\"NN Train Time: \", end - start,\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39ff2ac-1b0b-4143-8eb7-89378148bdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_filename = \"pickle_nn_hyper_model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a792de-928c-471f-806c-98c74e65dd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_filename = \"pickle_nn_hyper_model.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7ae273-8fea-4057-94a8-b900f679dd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "test_loss, test_acc = model.evaluate(test_data, test_label_cat)\n",
    "print(\"Test Loss: {}, Test Accuracy: {}\".format(test_loss, test_acc))   \n",
    "end = time.time()\n",
    "print(\"NN Predict Time: \", end - start,\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba5be12-57e5-4e3b-8dea-48ad3aeff3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "x_test = test_data\n",
    "y_true = test_label\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "end = time.time()\n",
    "print(\"NN Predict Time: \", end - start,\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ef7527-d318-4a8d-8a2a-daaec3a3c372",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_true, y_pred_classes)\n",
    "plot_confusion_matrix(cm, [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf329671-fa70-4f6a-bd69-6eae34f601d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = (y_pred_classes - y_true != 0)\n",
    "y_pred_classes_errors = y_pred_classes[errors]\n",
    "y_pred_errors = y_pred[errors]\n",
    "y_true_errors = y_true[errors]\n",
    "x_test_errors = x_test[errors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83ebfb7-b252-4bad-8489-5e0840c75744",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_errors_probability = np.max(y_pred_errors, axis=1)\n",
    "true_probability_errors = np.diagonal(np.take(y_pred_errors, y_true_errors, axis=1))\n",
    "diff_errors_pred_true = y_pred_errors_probability - true_probability_errors\n",
    "\n",
    "# Get list of indices of sorted differences\n",
    "sorted_idx_diff_errors = np.argsort(diff_errors_pred_true)\n",
    "top_idx_diff_errors = sorted_idx_diff_errors[-20:] # 5 last ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d71732-bebb-4816-b632-2d984499afa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Top Errors\n",
    "num = len(top_idx_diff_errors)\n",
    "f, ax = plt.subplots(1, num, figsize=(100,30))\n",
    "\n",
    "for i in range(0, num):\n",
    "  idx = top_idx_diff_errors[i]\n",
    "  sample = x_test_errors[idx].reshape(28,28)\n",
    "  y_t = y_true_errors[idx]\n",
    "  y_p = y_pred_classes_errors[idx]\n",
    "  ax[i].imshow(sample, cmap='gray')\n",
    "  ax[i].set_title(\"Predicted label :{}\\nTrue label: {}\".format(y_p, y_t), fontsize=22)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
